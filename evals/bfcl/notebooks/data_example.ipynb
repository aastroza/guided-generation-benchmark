{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "import instructor\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'simple'\n",
    "df = pd.read_json(f'../data/raw/gorilla_openfunctions_v1_test_{category}.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In a texas holdem game, Who won in the poker game with players Alex, Sam, Robert and Steve given the cards Alex':['A of spades', 'K of spades'], 'Sam': ['2 of diamonds', '3 of clubs'], 'Robert': ['Q of hearts', '10 of hearts'], 'Steve': ['4 of spades', '5 of spades']?\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = 337\n",
    "question = df.loc[pos]['question']\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'poker_game_winner',\n",
       " 'description': 'Identify the winner in a poker game based on the cards.',\n",
       " 'parameters': {'type': 'dict',\n",
       "  'properties': {'players': {'type': 'array',\n",
       "    'items': {'type': 'string'},\n",
       "    'description': 'Names of the players in a list.'},\n",
       "   'cards': {'type': 'dict',\n",
       "    'description': 'An object containing the player name as key and the cards as values in a list.'},\n",
       "   'type': {'type': 'string',\n",
       "    'description': \"Type of poker game. Defaults to 'Texas Holdem'\"}},\n",
       "  'required': ['players', 'cards']}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions = df.loc[pos]['function']\n",
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterator</th>\n",
       "      <th>category</th>\n",
       "      <th>question</th>\n",
       "      <th>pydantic_model_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>simple</td>\n",
       "      <td>Find the area of a triangle with a base of 10 ...</td>\n",
       "      <td>simple\\model_000.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>simple</td>\n",
       "      <td>Calculate the factorial of 5 using math functi...</td>\n",
       "      <td>simple\\model_001.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>simple</td>\n",
       "      <td>Calculate the hypotenuse of a right triangle g...</td>\n",
       "      <td>simple\\model_002.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>simple</td>\n",
       "      <td>Find the roots of a quadratic equation with co...</td>\n",
       "      <td>simple\\model_003.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>simple</td>\n",
       "      <td>Solve a quadratic equation where a=2, b=6, and...</td>\n",
       "      <td>simple\\model_004.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iterator category                                           question  \\\n",
       "0         0   simple  Find the area of a triangle with a base of 10 ...   \n",
       "1         1   simple  Calculate the factorial of 5 using math functi...   \n",
       "2         2   simple  Calculate the hypotenuse of a right triangle g...   \n",
       "3         3   simple  Find the roots of a quadratic equation with co...   \n",
       "4         4   simple  Solve a quadratic equation where a=2, b=6, and...   \n",
       "\n",
       "   pydantic_model_file  \n",
       "0  simple\\model_000.py  \n",
       "1  simple\\model_001.py  \n",
       "2  simple\\model_002.py  \n",
       "3  simple\\model_003.py  \n",
       "4  simple\\model_004.py  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models = pd.read_csv(f'../data/processed/pydantic_models.csv')\n",
    "df_models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = df_models[df_models['question'] == question]['pydantic_model_file'].values[0]\n",
    "\n",
    "pydantic_model_file = Path(\"..\").resolve() / \"data/processed\" / \"pydantic_models\" / model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_model_from_path(file_path: Path):\n",
    "    # Ensure the directory of the file is in sys.path\n",
    "    module_dir = file_path.parent\n",
    "    if str(module_dir) not in sys.path:\n",
    "        sys.path.append(str(module_dir))\n",
    "\n",
    "    # Create a module spec from the file location\n",
    "    spec = importlib.util.spec_from_file_location(file_path.stem, file_path)\n",
    "    if spec is None:\n",
    "        raise ImportError(f\"Could not load spec for module at {file_path}\")\n",
    "\n",
    "    # Load the module from spec\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "\n",
    "    attributes = [name for name, value in module.__dict__.items()\n",
    "              if not name.startswith(\"__\") and name not in [\"Field\", \"BaseModel\", \"annotations\", \"Enum\", \"Optional\", \"Any\", \"Dict\", \"List\"]]\n",
    "\n",
    "\n",
    "    # Access the Model object\n",
    "    if hasattr(module, attributes[-1]):\n",
    "        return getattr(module, attributes[-1])\n",
    "    else:\n",
    "        raise AttributeError(\n",
    "            f\"Module at {file_path} does not have an object named '{attributes[0]}'\"\n",
    "        )\n",
    "\n",
    "\n",
    "Model = import_model_from_path(pydantic_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_337.PokerGameWinner"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt_by_languge(prompt, test_category):\n",
    "    if test_category == \"java\":\n",
    "        prompt = prompt + \"\\n Note that the provided function is in Java 8 SDK syntax.\"\n",
    "    elif test_category == \"javascript\":\n",
    "        prompt = prompt + \"\\n Note that the provided function is in JavaScript.\"\n",
    "    else:\n",
    "        prompt = prompt + \"\\n Note that the provided function is in Python.\"\n",
    "    return prompt\n",
    "\n",
    "def language_specific_pre_processing(function, test_category, string_param):\n",
    "    for item in function:\n",
    "        properties = item[\"parameters\"][\"properties\"]\n",
    "        if test_category == \"java\":\n",
    "            for key, value in properties.items():\n",
    "                if value[\"type\"] == \"Any\" or value[\"type\"] == \"any\":\n",
    "                    properties[key][\n",
    "                        \"description\"\n",
    "                    ] += \"This parameter can be of any type of Java object.\"\n",
    "                    properties[key][\"description\"] += (\n",
    "                        \"This is Java\" + value[\"type\"] + \" in string representation.\"\n",
    "                    )\n",
    "        elif test_category == \"javascript\":\n",
    "            for key, value in properties.items():\n",
    "                if value[\"type\"] == \"Any\" or value[\"type\"] == \"any\":\n",
    "                    properties[key][\n",
    "                        \"description\"\n",
    "                    ] += \"This parameter can be of any type of Javascript object.\"\n",
    "                else:\n",
    "                    if \"description\" not in properties[key]:\n",
    "                        properties[key][\"description\"] = \"\"\n",
    "                    properties[key][\"description\"] += (\n",
    "                        \"This is Javascript \"\n",
    "                        + value[\"type\"]\n",
    "                        + \" in string representation.\"\n",
    "                    )\n",
    "        return function\n",
    "    \n",
    "SYSTEM_PROMPT_FOR_CHAT_MODEL = \"\"\"\"\n",
    "    You are an expert in composing functions. You are given a question and a set of possible functions. \n",
    "    Based on the question, you will need to make one or more function/tool calls to achieve the purpose. \n",
    "    If none of the function can be used, point it out. If the given question lacks the parameters required by the function,\n",
    "    also point it out. You should only return the function call in tools call sections.\n",
    "    \"\"\"\n",
    "\n",
    "USER_PROMPT_FOR_CHAT_MODEL = \"\"\"\n",
    "    Questions:{user_prompt}\\nHere is a list of functions in JSON format that you can invoke:\\n{functions}. \n",
    "    Should you decide to return the function call(s),Put it in the format of [func1(params_name=params_value, params_name2=params_value2...), func2(params)]\\n\n",
    "    NO other text MUST be included. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = augment_prompt_by_languge(question,category)\n",
    "functions_str = language_specific_pre_processing([functions],category,False)\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": SYSTEM_PROMPT_FOR_CHAT_MODEL,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Questions:\"\n",
    "        + USER_PROMPT_FOR_CHAT_MODEL.format(\n",
    "            user_prompt=prompt, functions=str(functions_str)\n",
    "        ),\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "InstructorRetryException",
     "evalue": "1 validation error for PokerGameWinner\ncards\n  Field required [type=missing, input_value={'players': ['Alex', 'Sam', 'Robert', 'Steve']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\guided-generation-torch\\Lib\\site-packages\\instructor\\retry.py:158\u001b[0m, in \u001b[0;36mretry_sync\u001b[1;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001b[0m\n\u001b[0;32m    157\u001b[0m     response \u001b[38;5;241m=\u001b[39m update_total_usage(response, total_usage)\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocess_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ValidationError, JSONDecodeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\guided-generation-torch\\Lib\\site-packages\\instructor\\process_response.py:147\u001b[0m, in \u001b[0;36mprocess_response\u001b[1;34m(response, response_model, stream, validation_context, strict, mode)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m--> 147\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# ? This really hints at the fact that we need a better way of\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# ? attaching usage data and the raw response to the model we return.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\guided-generation-torch\\Lib\\site-packages\\instructor\\function_calls.py:107\u001b[0m, in \u001b[0;36mOpenAISchema.from_response\u001b[1;34m(cls, completion, validation_context, strict, mode)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m {Mode\u001b[38;5;241m.\u001b[39mTOOLS, Mode\u001b[38;5;241m.\u001b[39mMISTRAL_TOOLS}:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m {Mode\u001b[38;5;241m.\u001b[39mJSON, Mode\u001b[38;5;241m.\u001b[39mJSON_SCHEMA, Mode\u001b[38;5;241m.\u001b[39mMD_JSON}:\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\guided-generation-torch\\Lib\\site-packages\\instructor\\function_calls.py:192\u001b[0m, in \u001b[0;36mOpenAISchema.parse_tools\u001b[1;34m(cls, completion, validation_context, strict)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    190\u001b[0m     tool_call\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_schema[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m    191\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool name does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_validate_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_call\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\guided-generation-torch\\Lib\\site-packages\\pydantic\\main.py:561\u001b[0m, in \u001b[0;36mBaseModel.model_validate_json\u001b[1;34m(cls, json_data, strict, context)\u001b[0m\n\u001b[0;32m    560\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for PokerGameWinner\ncards\n  Field required [type=missing, input_value={'players': ['Alex', 'Sam', 'Robert', 'Steve']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInstructorRetryException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m client \u001b[38;5;241m=\u001b[39m instructor\u001b[38;5;241m.\u001b[39mfrom_openai(OpenAI())\n\u001b[1;32m----> 3\u001b[0m model_response, completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_with_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4-0125-preview\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\guided-generation-torch\\Lib\\site-packages\\instructor\\client.py:143\u001b[0m, in \u001b[0;36mInstructor.create_with_completion\u001b[1;34m(self, messages, response_model, max_retries, validation_context, strict, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_with_completion\u001b[39m(\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    135\u001b[0m     messages: List[ChatCompletionMessageParam],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    141\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[T, ChatCompletion \u001b[38;5;241m|\u001b[39m Any]:\n\u001b[0;32m    142\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_kwargs(kwargs)\n\u001b[1;32m--> 143\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, model\u001b[38;5;241m.\u001b[39m_raw_response\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\guided-generation-torch\\Lib\\site-packages\\instructor\\patch.py:150\u001b[0m, in \u001b[0;36mpatch.<locals>.new_create_sync\u001b[1;34m(response_model, validation_context, max_retries, strict, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_create_sync\u001b[39m(\n\u001b[0;32m    140\u001b[0m     response_model: Type[T_Model] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: T_ParamSpec\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[0;32m    146\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_Model:\n\u001b[0;32m    147\u001b[0m     response_model, new_kwargs \u001b[38;5;241m=\u001b[39m handle_response_model(\n\u001b[0;32m    148\u001b[0m         response_model\u001b[38;5;241m=\u001b[39mresponse_model, mode\u001b[38;5;241m=\u001b[39mmode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    149\u001b[0m     )\n\u001b[1;32m--> 150\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mretry_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\guided-generation-torch\\Lib\\site-packages\\instructor\\retry.py:152\u001b[0m, in \u001b[0;36mretry_sync\u001b[1;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_retries must be an int or a `tenacity.Retrying` object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\guided-generation-torch\\Lib\\site-packages\\tenacity\\__init__.py:347\u001b[0m, in \u001b[0;36mBaseRetrying.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    345\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, args\u001b[38;5;241m=\u001b[39m(), kwargs\u001b[38;5;241m=\u001b[39m{})\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    349\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m AttemptManager(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\guided-generation-torch\\Lib\\site-packages\\tenacity\\__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    323\u001b[0m     retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\guided-generation-torch\\Lib\\site-packages\\tenacity\\__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\guided-generation-torch\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\guided-generation-torch\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\anaconda3\\envs\\guided-generation-torch\\Lib\\site-packages\\instructor\\retry.py:173\u001b[0m, in \u001b[0;36mretry_sync\u001b[1;34m(func, response_model, validation_context, args, kwargs, max_retries, strict, mode)\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m {Mode\u001b[38;5;241m.\u001b[39mANTHROPIC_TOOLS, Mode\u001b[38;5;241m.\u001b[39mANTHROPIC_JSON}:\n\u001b[0;32m    170\u001b[0m                     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m merge_consecutive_messages(\n\u001b[0;32m    171\u001b[0m                         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    172\u001b[0m                     )\n\u001b[1;32m--> 173\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m InstructorRetryException(\n\u001b[0;32m    174\u001b[0m                     e,\n\u001b[0;32m    175\u001b[0m                     last_completion\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[0;32m    176\u001b[0m                     n_attempts\u001b[38;5;241m=\u001b[39mattempt\u001b[38;5;241m.\u001b[39mretry_state\u001b[38;5;241m.\u001b[39mattempt_number,\n\u001b[0;32m    177\u001b[0m                     messages\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    178\u001b[0m                     total_usage\u001b[38;5;241m=\u001b[39mtotal_usage,\n\u001b[0;32m    179\u001b[0m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InstructorRetryException(\n\u001b[0;32m    182\u001b[0m         e,\n\u001b[0;32m    183\u001b[0m         last_completion\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m         total_usage\u001b[38;5;241m=\u001b[39mtotal_usage,\n\u001b[0;32m    187\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mInstructorRetryException\u001b[0m: 1 validation error for PokerGameWinner\ncards\n  Field required [type=missing, input_value={'players': ['Alex', 'Sam', 'Robert', 'Steve']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing"
     ]
    }
   ],
   "source": [
    "client = instructor.from_openai(OpenAI())\n",
    "\n",
    "model_response, completion = client.chat.completions.create_with_completion(\n",
    "    model=\"gpt-4-0125-preview\",\n",
    "    response_model=Model,\n",
    "    messages=messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "def format_result(function_name, result):\n",
    "    # This method is used to format the result in a standard way.\n",
    "    args_string = ', '.join(\n",
    "        [f\"{key}='{value}'\" if isinstance(value, str) else \n",
    "         f\"{key}='{value.value}'\" if isinstance(value, Enum) and isinstance(value.value, str) else \n",
    "         f\"{key}={value.value}\" if isinstance(value, Enum) else \n",
    "         f\"{key}={value}\"\n",
    "         for key, value in result.dict().items()]\n",
    "    )\n",
    "    # Creating the output string with the function name and arguments\n",
    "    output_string = f'[{function_name}({args_string})]'\n",
    "    return output_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = model_response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp: <class 'int'>\n",
      "volume: <class 'int'>\n",
      "gas: <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "# see data types of each value of model_dict\n",
    "for key, value in model_dict.items():\n",
    "    print(f\"{key}: {type(value)}\")\n",
    "    # if it's Enum, print value\n",
    "    if isinstance(value, Enum):\n",
    "        print(value.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[holi(temp=298, volume=10, gas=None)]'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_result('holi', model_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guided-generation-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
