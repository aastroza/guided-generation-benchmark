{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creting Pydantic Models from BFCL dataset\n",
    "\n",
    "Code based on this repository:\n",
    "> Connesson, RÃ©mi. (Apr 2024). Outlines Function Call Gorilla Leaderboard Experiment. GitHub. https://github.com/remiconnesson/outlines-func-call-gorilla-leaderboard-experiment/tree/main.\n",
    "\n",
    "And these files:\n",
    "\n",
    "https://github.com/ShishirPatil/gorilla/blob/1d8d51d0d091c33e730d38745745005c9bc7dfc0/berkeley-function-call-leaderboard/model_handler/constant.py#L13\n",
    "\n",
    "\n",
    "https://github.com/ShishirPatil/gorilla/blob/1d8d51d0d091c33e730d38745745005c9bc7dfc0/berkeley-function-call-leaderboard/model_handler/utils.py#L9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['simple', 'java', 'javascript']\n",
    "pydantic_models_dir = Path(\"..\").resolve() / \"data/processed\" / \"pydantic_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "GORILLA_TO_OPENAPI = {\n",
    "    \"integer\": \"integer\",\n",
    "    \"number\": \"number\",\n",
    "    \"float\": \"number\",\n",
    "    \"string\": \"string\",\n",
    "    \"boolean\": \"boolean\",\n",
    "    \"bool\": \"boolean\",\n",
    "    \"array\": \"array\",\n",
    "    \"list\": \"array\",\n",
    "    \"dict\": \"object\",\n",
    "    \"object\": \"object\",\n",
    "    \"tuple\": \"array\",\n",
    "    \"any\": \"string\",\n",
    "    \"byte\": \"integer\",\n",
    "    \"short\": \"integer\",\n",
    "    \"long\": \"integer\",\n",
    "    \"double\": \"number\",\n",
    "    \"char\": \"string\",\n",
    "    \"ArrayList\": \"array\",\n",
    "    \"Array\": \"array\",\n",
    "    \"HashMap\": \"object\",\n",
    "    \"Hashtable\": \"object\",\n",
    "    \"Queue\": \"array\",\n",
    "    \"Stack\": \"array\",\n",
    "    \"Any\": \"string\",\n",
    "    \"String\": \"string\",\n",
    "    \"Bigint\": \"integer\",\n",
    "}\n",
    "\n",
    "def _cast_to_openai_type(properties, mapping, test_category):\n",
    "    for key, value in properties.items():\n",
    "        if \"type\" not in value:\n",
    "            properties[key][\"type\"] = \"string\"\n",
    "        else:\n",
    "            var_type = value[\"type\"]\n",
    "            if mapping == GORILLA_TO_OPENAPI and var_type == \"float\":\n",
    "                properties[key][\"format\"] = \"float\"\n",
    "                properties[key][\"description\"] += \" This is a float type value.\"\n",
    "            if var_type in mapping:\n",
    "                properties[key][\"type\"] = mapping[var_type]\n",
    "            else:\n",
    "                properties[key][\"type\"] = \"string\"\n",
    "\n",
    "        # Currently support:\n",
    "        # - list of any\n",
    "        # - list of list of any\n",
    "        # - list of dict\n",
    "        # - list of list of dict\n",
    "        # - dict of any\n",
    "\n",
    "        if properties[key][\"type\"] == \"array\" or properties[key][\"type\"] == \"object\":\n",
    "            if \"properties\" in properties[key]:\n",
    "                properties[key][\"properties\"] = _cast_to_openai_type(\n",
    "                    properties[key][\"properties\"], mapping, test_category\n",
    "                )\n",
    "            elif \"items\" in properties[key]:\n",
    "                properties[key][\"items\"][\"type\"] = mapping[\n",
    "                    properties[key][\"items\"][\"type\"]\n",
    "                ]\n",
    "                if (\n",
    "                    properties[key][\"items\"][\"type\"] == \"array\"\n",
    "                    and \"items\" in properties[key][\"items\"]\n",
    "                ):\n",
    "                    properties[key][\"items\"][\"items\"][\"type\"] = mapping[\n",
    "                        properties[key][\"items\"][\"items\"][\"type\"]\n",
    "                    ]\n",
    "                elif (\n",
    "                    properties[key][\"items\"][\"type\"] == \"object\"\n",
    "                    and \"properties\" in properties[key][\"items\"]\n",
    "                ):\n",
    "                    properties[key][\"items\"][\"properties\"] = _cast_to_openai_type(\n",
    "                        properties[key][\"items\"][\"properties\"], mapping, test_category\n",
    "                    )\n",
    "    return properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=['iterator', 'category', 'question', 'pydantic_model_file'])\n",
    "\n",
    "for category in categories:\n",
    "    df = pd.read_json(f'../data/raw/gorilla_openfunctions_v1_test_{category}.json', lines=True)\n",
    "\n",
    "    get_model_file = lambda i: pydantic_models_dir / category / f\"model_{i:03d}.py\"\n",
    "    \n",
    "    for i, _ in df.iterrows():\n",
    "\n",
    "        schema = json.dumps({\n",
    "            \"title\": df.loc[i, \"function\"][\"name\"],\n",
    "            \"type\": \"object\",\n",
    "            \"description\": df.loc[i, \"function\"][\"description\"],\n",
    "            \"properties\": _cast_to_openai_type(df.loc[i, \"function\"][\"parameters\"][\"properties\"], GORILLA_TO_OPENAPI, category),\n",
    "            \"required\": df.loc[i, \"function\"][\"parameters\"][\"required\"]\n",
    "        }, indent=2)\n",
    "\n",
    "        with open(\"json_schema.json\", \"w\") as f:\n",
    "            f.write(schema)\n",
    "                    \n",
    "        model_file = get_model_file(i)\n",
    "        !datamodel-codegen  --input json_schema.json --input-file-type jsonschema --output { model_file }\n",
    "        \n",
    "         # Create a temporary DataFrame and concatenate it\n",
    "        temp_df = pd.DataFrame({\n",
    "            'iterator': [i],\n",
    "            'category': [category],\n",
    "            'question': [df.loc[i, \"question\"]],\n",
    "            'pydantic_model_file': [str(model_file)]\n",
    "        })\n",
    "        df_results = pd.concat([df_results, temp_df], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "\n",
    "df_results.to_csv('../data/processed/pydantic_models.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guided-generation-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
